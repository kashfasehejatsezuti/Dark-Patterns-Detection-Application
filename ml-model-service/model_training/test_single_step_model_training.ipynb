{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "974dac2f",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e52d970f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial DataFrame count: 290\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file from the model_training folder\n",
    "df = pd.read_csv(\"../model_training/dataset.csv\")\n",
    "print(f\"Initial DataFrame count: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f30a09b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of selected types\n",
    "selected_types = [\"Not Dark Pattern\", \"Fake Scarcity\", \"Fake Social Proof\", \"Fake Urgency\", \"Misdirection\"]\n",
    "\n",
    "# Create a boolean mask\n",
    "mask = df['Type'].isin(selected_types)\n",
    "\n",
    "# Apply the mask to filter the DataFrame\n",
    "selected_df = df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "acde11f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataFrame count: 222\n",
      "Test DataFrame count: 56\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "train_df, test_df = train_test_split(selected_df, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Train DataFrame count: {len(train_df)}\")\n",
    "print(f\"Test DataFrame count: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d576406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipelines for each algorithm\n",
    "algorithms = {\n",
    "    \"Multinomial Naive Bayes\": make_pipeline(TfidfVectorizer(), MultinomialNB()),\n",
    "    \"Support Vector Machines\": make_pipeline(TfidfVectorizer(), SVC(kernel='linear')),\n",
    "    \"Random Forest\": make_pipeline(TfidfVectorizer(), RandomForestClassifier())\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "68e71619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a folder for trained models if it doesn't exist\n",
    "models_folder = \"trained_models\"\n",
    "os.makedirs(models_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58f43d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes Accuracy: 0.50\n",
      "Support Vector Machines Accuracy: 0.70\n",
      "Random Forest Accuracy: 0.62\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate each model\n",
    "for algo_name, model in algorithms.items():\n",
    "    # Drop rows with missing values in the 'Text' column\n",
    "    train_df = train_df.dropna(subset=['Text'])\n",
    "\n",
    "    # Ensure 'Text' column has string data type\n",
    "    train_df['Text'] = train_df['Text'].astype(str)\n",
    "\n",
    "    # Reset the index of the DataFrame\n",
    "    train_df = train_df.reset_index(drop=True)\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(train_df['Text'], train_df['Type'])\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    predictions = model.predict(test_df['Text'])\n",
    "    accuracy = accuracy_score(test_df['Type'], predictions)\n",
    "\n",
    "    # Save the trained model to a file in the trained_models folder\n",
    "    model_path = os.path.join(models_folder, f'{algo_name.lower().replace(\" \", \"_\")}_model.joblib')\n",
    "    dump(model, model_path)\n",
    "\n",
    "    print(f\"{algo_name} Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "750192c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to predict: Accept all\n",
      "Multinomial Naive Bayes: ['Not Dark Pattern']\n",
      "Support Vector Machines: ['Not Dark Pattern']\n",
      "Random Forest: ['Not Dark Pattern']\n"
     ]
    }
   ],
   "source": [
    "user_input_text = \"Accept all\"\n",
    "print(f\"Text to predict: {user_input_text}\")\n",
    "\n",
    "# Load and make predictions with each model\n",
    "for algo_name, model in algorithms.items():\n",
    "    # Load the saved model\n",
    "    model_path = os.path.join(models_folder, f'{algo_name.lower().replace(\" \", \"_\")}_model.joblib')\n",
    "    loaded_model = load(model_path)\n",
    "    \n",
    "    # Make predictions\n",
    "    predicted_type = loaded_model.predict([user_input_text])\n",
    "    \n",
    "    print(f\"{algo_name}: {predicted_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea004e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
